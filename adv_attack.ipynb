from absl import app, flags
from easydict import EasyDict
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision

from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method
from cleverhans.torch.attacks.projected_gradient_descent import (
    projected_gradient_descent,
)


# Basic CNN Block

class CNN(torch.nn.Module):
    """Basic CNN architecture."""

    def __init__(self, in_channels=1):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, 64, 8, 1)
        self.conv2 = nn.Conv2d(64, 128, 6, 2)
        self.conv3 = nn.Conv2d(128, 128, 5, 2)
        self.fc = nn.Linear(128 * 3 * 3, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = F.relu(self.conv3(x))
        x = x.view(-1, 128 * 3 * 3)
        x = self.fc(x)
        return x

# Load CIFAR10 utils

def ld_cifar10():

    train_transforms = torchvision.transforms.Compose(
        [torchvision.transforms.ToTensor()]
    )
    test_transforms = torchvision.transforms.Compose(
        [torchvision.transforms.ToTensor()]
    )
    train_dataset = torchvision.datasets.CIFAR10(
        root="/tmp/data", train=True, transform=train_transforms, download=True
    )
    test_dataset = torchvision.datasets.CIFAR10(
        root="/tmp/data", train=False, transform=test_transforms, download=True
    )
    train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=128, shuffle=True, num_workers=2
    )
    test_loader = torch.utils.data.DataLoader(
        test_dataset, batch_size=128, shuffle=False, num_workers=2
    )
    return EasyDict(train=train_loader, test=test_loader)


data = ld_cifar10()
device = "cuda" if torch.cuda.is_available() else "cpu"





# Train with/without adversarial examples

def train_model(net, data, adv_train, n_epochs):
    net.train()
    loss_fn = torch.nn.CrossEntropyLoss(reduction="mean")
    optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)

    for epoch in range(1, 1 + n_epochs):
        train_loss = 0.0
        for x, y in data.train:
            x, y = x.to(device), y.to(device)
            if adv_train:
                # Replace clean example with adversarial example for adversarial training
                x = projected_gradient_descent(net, x, 0.3, 0.01, 40, np.inf)
            optimizer.zero_grad()
            loss = loss_fn(net(x), y)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        print(
            "epoch: {}/{}, train loss: {:.3f}".format(
                epoch, n_epochs, train_loss
            )
        )
    net.eval()
    report = EasyDict(nb_test=0, correct=0, correct_fgm=0, correct_pgd=0)
    for x, y in data.test:
        x, y = x.to(device), y.to(device)
        x_fgm = fast_gradient_method(net, x, 0.3, np.inf)
        x_pgd = projected_gradient_descent(net, x, 0.3, 0.01, 40, np.inf)
        _, y_pred = net(x).max(1)  # model prediction on clean examples
        _, y_pred_fgm = net(x_fgm).max(
            1
        )  # model prediction on FGM adversarial examples
        _, y_pred_pgd = net(x_pgd).max(
            1
        )  # model prediction on PGD adversarial examples
        report.nb_test += y.size(0)
        report.correct += y_pred.eq(y).sum().item()
        report.correct_fgm += y_pred_fgm.eq(y).sum().item()
        report.correct_pgd += y_pred_pgd.eq(y).sum().item()
    print(
        "test acc on clean examples (%): {:.3f}".format(
            report.correct / report.nb_test * 100.0
        )
    )
    print(
        "test acc on FGM adversarial examples (%): {:.3f}".format(
            report.correct_fgm / report.nb_test * 100.0
        )
    )
    print(
        "test acc on PGD adversarial examples (%): {:.3f}".format(
            report.correct_pgd / report.nb_test * 100.0
        )
    )
    return report



set adv_train = False/True respectively to train with/without adversarial examples


net = CNN(in_channels=3)
if device == "cuda":
    net = net.cuda()

report_vanilla = train_model(net, data, False, 50)

net = CNN(in_channels=3)
if device == "cuda":
    net = net.cuda()

report_adv = train_model(net, data, True, 50)

from geomloss import SamplesLoss

# Train with Sickhorn/Wasserstein Loss

def train_model_wloss(net, data, adv_train, n_epochs, w_true):
    net.train()
    
    
    loss_fn = torch.nn.CrossEntropyLoss(reduction="mean")
    optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)
    
    print('Training for {} epochs'.format(n_epochs))
    
    for epoch in range(1, 1+ n_epochs):
        train_loss = 0.0
        for x, y in data.train:
            x, y = x.to(device), y.to(device)
            
            optimizer.zero_grad()

            loss1 = loss_fn(net(x), y)
            if adv_train:
                x_perturbed = projected_gradient_descent(net, x, 0.3, 0.01, 40, np.inf)
                
            
            loss2 = loss_fn(net(x_perturbed),y)
            if w_true:
                x_o = net(x)
                x_op = net(x_perturbed)
                
                x_o = x_o.view(-1,len(x_o))
                x_op = x_o.view(-1, len(x_op))
                sl = SamplesLoss()
                sloss = sl(x_o, x_op)
                loss = loss1 +sloss
            else:
                loss = loss1 + loss2
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        print(
            "epoch: {}/{}, train loss: {:.3f}".format(
                epoch, n_epochs, train_loss
            )
        )
        
    net.eval()
    report = EasyDict(nb_test=0, correct=0, correct_fgm=0, correct_pgd=0)
    for x, y in data.test:
        x, y = x.to(device), y.to(device)
        x_fgm = fast_gradient_method(net, x, 0.3, np.inf)
        x_pgd = projected_gradient_descent(net, x, 0.3, 0.01, 40, np.inf)
        _, y_pred = net(x).max(1)  # model prediction on clean examples
        _, y_pred_fgm = net(x_fgm).max(
            1
        )  # model prediction on FGM adversarial examples
        _, y_pred_pgd = net(x_pgd).max(
            1
        )  # model prediction on PGD adversarial examples
        report.nb_test += y.size(0)
        report.correct += y_pred.eq(y).sum().item()
        report.correct_fgm += y_pred_fgm.eq(y).sum().item()
        report.correct_pgd += y_pred_pgd.eq(y).sum().item()
    print(
        "test acc on clean examples (%): {:.3f}".format(
            report.correct / report.nb_test * 100.0
        )
    )
    print(
        "test acc on FGM adversarial examples (%): {:.3f}".format(
            report.correct_fgm / report.nb_test * 100.0
        )
    )
    print(
        "test acc on PGD adversarial examples (%): {:.3f}".format(
            report.correct_pgd / report.nb_test * 100.0
        )
    )
    return report



#set n_epochs to number of epochs to train

net = CNN(in_channels=3)
if device == "cuda":
    net = net.cuda()

report_adv_wloss = train_model_wloss(net, data, True, 5, True)
